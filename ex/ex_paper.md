# 5. 实验与仿真结果

本章通过系统性的实验验证BFT4Agent协议在实际开放环境下的有效性与鲁棒性。我们构建了完整的仿真实验平台，从端到端延迟、可扩展性以及拜占庭容错能力三个维度对协议进行全面评估。实验结果表明，相较于传统基线方案，本协议在保证安全性的前提下，实现了可接受的延迟水平，并展现出对恶意节点的强鲁棒性。

## 5.1 实验设计与配置

我们基于Python构建了分布式多智能体协同仿真平台，实现BFT4Agent协议的完整执行流程，包括P2P网络通信、三阶段共识机制、视图切换协议以及基于信誉的加权投票机制。平台核心组件包括：1）智能体模拟器：支持多种LLM后端接入，包括真实LLM API（如Q-wen、GLM等最新系列）和LLM Mock模拟器；2）网络仿真器：模拟半同步网络环境，消息延迟范围[10, 100]ms，丢包率1%。

实验采用4、7、10、20四种节点规模，满足拜占庭容错阈值 $n \geq 3f + 1$。测试场景包括多种恶意比例变化实验。恶意节点行为包括发送错误推理结果、拒绝投票、协调攻击等典型拜占庭行为。实验负载采用数学与逻辑推理任务，具有明确的正确性判定标准，适合验证语义一致性校验能力。每个配置运行5个独立任务，结果取平均值。

对比基线包括：（1）传统BFT协议（PBFT）：使用Mock模拟器替代真实LLM，用于区分协议开销和LLM推理开销；（2）单智能体系统：直接调用单一LLM，无分布式共识机制，代表最优延迟但无安全性的场景。

## 5.2 端到端延迟实验

本节分析BFT4Agent协议的延迟特性与可扩展性。在不同节点规模，分别测试全诚实场景和14%恶意节点比例下的系统性能。如表1所示，在全诚实场景下，系统平均延迟范围为41.16-56.13秒，且随节点规模增长呈现亚线性趋势：当节点数从4增至20（增长5倍）时，延迟仅从44.31秒增至56.13秒（增长26.5%）。这一优异的可扩展性归因于仅主节点执行完整LLM推理、验证节点仅进行轻量级二元校验的设计优化。

图1展示了协议与基线方案的对比。使用Mock模拟器的传统BFT协议（Baseline）延迟仅为1.48-1.58秒，而引入真实LLM推理后（Ours），延迟增至41-56秒。这30-40倍的增量完全来源于LLM推理开销，验证了共识协议本身开销极小（<1%）。值得注意的是，在小规模场景（4-7节点）下，即使存在14%恶意节点，协议延迟仅增加约6%，表明容错机制对正常路径性能影响微弱。然而，在10节点以上规模时，14%恶意比例导致延迟急剧增加。深入分析发现，这是由于恶意节点频繁触发视图切换所致。每次视图切换需经历超时等待（30秒）、重新选举和重新推理（约15-25秒），引入约45-55秒额外开销。尽管如此，协议仍能保证最终一致性，成功率达100%。图2揭示了延迟组成，Mock的对比实验代表非后端LLM的调用延迟也会随着恶意节点数量的增加而攀升，但从比例上来说，LLM的调用延迟仍占据主要耗时。

## 5.3 拜占庭环境下的协议性能与鲁棒性

为评估协议的拜占庭容错能力，我们在20节点固定规模下，测试了恶意节点比例从5%至30%（1至6个恶意节点）时的系统性能。如图3所示，系统总延迟从5%恶意时的129.94秒线性增长至30%时的525.67秒，增长幅度达304%。延迟增长的主要原因在于视图切换次数的递增：从5%恶意时的1.0次增至30%时的6.0次。每次视图切换引入约45-55秒额外开销，包括视图切换、VRF重新选举以及新主节点的完整LLM推理。

图4分解了共识开销与LLM调用开销随恶意比例的变化。红色区域的面积代表后端LLM的开销，其随着恶意节点比例增加而逐渐增大，但与其他开销（主要来自于共识开销）的比例维持稳定。因此，恶意比例会同步提升全因素开销。但在安全范围内（$n < 3f + 1$），BFT4Agents仍能保障最终共识的实现，充分验证了其容错能力。

实际应用中，开放网络环境的恶意节点比例通常低于10%，所有的实验中，单次LLM后端延迟平均值为21.48秒，由5.2小节数据可知，在20 Agents集群以内的场景中，本协议端到端延迟仅是不安全的直接Agent调用延迟的1.9~2.6倍，这对用户而言是可接收的，故BFT4Agents为需要高可信度的多智能体协作应用提供了可行的安全方案。


---

**表1 不同配置下的延迟统计结果**

| 配置 | 节点数 | 恶意比例 | 平均延迟(秒) | 标准差 | 最小值 | 最大值 | 成功率 |
|------|--------|----------|--------------|--------|--------|--------|--------|
| Baseline (Mock) | 4 | 0% | 1.504 | 0.155 | 1.271 | 1.678 | 100% |
| Baseline (Mock) | 7 | 14% | 1.556 | 0.078 | 1.431 | 1.633 | 100% |
| Ours (w/ LLM) | 4 | 0% | 44.306 | 10.276 | 31.843 | 58.565 | 100% |
| Ours (w/ LLM) | 4 | 14% | 47.109 | 13.871 | 26.571 | 65.209 | 100% |
| Ours (w/ LLM) | 7 | 0% | 41.161 | 8.871 | 31.984 | 54.458 | 100% |
| Ours (w/ LLM) | 7 | 14% | 43.330 | 11.946 | 27.860 | 56.540 | 100% |
| Ours (w/ LLM) | 10 | 0% | 45.813 | 12.215 | 33.243 | 61.819 | 100% |
| Ours (w/ LLM) | 10 | 14% | 133.183 | 25.519 | 104.288 | 162.634 | 100% |
| Ours (w/ LLM) | 20 | 0% | 56.130 | 15.799 | 40.699 | 74.786 | 100% |
| Ours (w/ LLM) | 20 | 14% | 215.102 | 48.568 | 176.788 | 296.002 | 100% |

**表2 不同恶意比例下的投票统计与视图切换**

| 恶意比例 | 恶意节点数 | 总延迟(秒) | Y票数 | N票数 | 视图切换次数 | 总消息数 | 成功率 |
|---------|-----------|-----------|-------|-------|-------------|---------|--------|
| 5% | 1 | 129.94 | 18 | 1 | 1.0 | 1240 | 100% |
| 10% | 2 | 214.94 | 17 | 2 | 2.0 | 1660 | 100% |
| 15% | 3 | 338.70 | 16 | 3 | 3.0 | 2080 | 100% |
| 20% | 4 | 375.24 | 15 | 4 | 4.0 | 2500 | 100% |
| 25% | 5 | 493.32 | 14 | 5 | 5.0 | 2920 | 100% |
| 30% | 6 | 525.67 | 13 | 6 | 6.0 | 3340 | 83.3% |

---

**图说明**

**图1** 延迟对比。横轴为节点数（4、7、10、20），纵轴为平均延迟（秒），对比BFT4Agent协议（使用真实LLM）与传统BFT协议（使用Mock模拟器）在不同节点规模和恶意比例下的性能。

**图2** 可扩展性分析（对数坐标）。展示系统延迟随节点规模增长的变化趋势，全诚实场景下延迟呈亚线性增长，验证了协议的可扩展性。

**图3** 延迟组成饼图。展示Pre-Prepare（主节点推理）、Prepare（验证校验）、Commit（结果聚合）三个阶段的延迟占比分布，Pre-Prepare阶段占据主要比例。

**图4** 恶意比例下的延迟分解（20节点系统）。展示不同恶意节点比例（5%-30%）下，Pre-Prepare、Prepare、Commit三个阶段的延迟变化，总延迟增长主要归因于视图切换次数增加。

**图5** 延迟分布箱线图。展示不同恶意比例下延迟的统计特征（最小值、最大值、中位数、四分位数），反映系统在拜占庭环境下的稳定性。
