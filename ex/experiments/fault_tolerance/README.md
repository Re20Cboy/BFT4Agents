# 容错边界测试实验 (Fault Tolerance Boundary Test)

## 实验概述

本实验旨在测试 **BFT4Agent 协议在面对刁钻问题（Tricky Questions）时的容错边界**，验证系统在"诚实LLM agent出错 + 恶意agent攻击"的双重压力下是否仍能达成共识。

### 核心创新点

与传统的BFT协议不同，**BFT4Agent协议中即使是诚实的LLM agent也可能投出错误的票**，原因包括：
- **LLM幻觉**：大模型可能产生事实性错误
- **理解偏差**：不同LLM对同一问题的理解可能不一致
- **知识盲区**：某些专业问题超出模型的知识范围
- **诱导性陷阱**：刁钻问题设计用于诱导错误推理

因此，本实验测试的是**真实的容错边界**，而非理论上的拜占庭容错阈值。

---

## 研究问题

1. **容错边界在哪里？** 当恶意节点比例接近理论阈值（1/3）时，系统能否仍达成共识？
2. **诚实agent出错的影响？** 当诚实LLM也投错票时，容错能力如何变化？
3. **Leader角色的作用？** Leader为诚实vs恶意时，系统表现有何差异？
4. **与理论预期对比？** 实际容错边界与理论值（f/n ≤ 1/3）的差距？

---

## 实验设计

### 固定参数

- **节点总数**：9个（满足 n = 3f + 1）
- **问题类型**：刁钻问题（Tricky Questions）
  - 逻辑陷阱题
  - 数学陷阱题
  - 概率/博弈论题
  - 知识盲区题
- **网络延迟**：[10, 100] ms
- **LLM后端**：Qwen/Zhipu/OpenAI（真实LLM）
- **任务数量**：每个配置5个问题（随机选择）

### 变化参数

| 实验组 | 恶意节点数 | 恶意比例 | Leader类型 | 测试目的 |
|--------|-----------|---------|-----------|---------|
| 组1    | 0         | 0%      | 诚实       | 基准测试：无恶意节点时的表现 |
| 组2    | 1         | 11%     | 诚实       | 轻度恶意 |
| 组3    | 1         | 11%     | 恶意       | 恶意Leader影响 |
| 组4    | 2         | 22%     | 诚实       | 中度恶意 |
| 组5    | 2         | 22%     | 恶意       | 恶意Leader + 中度恶意 |
| 组6    | 3         | 33%     | 诚实       | **临界测试：理论阈值** |
| 组7    | 3         | 33%     | 恶意       | 最坏情况：恶意Leader + 临界恶意 |

**总计**：7种配置 × 5个任务 = 35次共识过程

---

## 测量指标

### 1. 核心指标

| 指标 | 说明 | 预期趋势 |
|------|------|---------|
| **共识成功率** | 达成共识的任务比例 | 随恶意比例下降，33%时显著下降 |
| **平均延迟** | 从任务提交到结果输出的时间 | 随恶意比例增加（更多视图切换） |
| **视图切换次数** | Leader被替换的次数 | 恶意Leader时更高 |

### 2. 深度指标（需扩展实现）

| 指标 | 说明 | 价值 |
|------|------|------|
| **诚实agent错误率** | 诚实agent投N票的比例 | 衡量问题难度 |
| **恶意agent欺骗率** | 恶意agent投Y票但答案错误的比例 | 衡量攻击有效性 |
| **最终答案准确率** | 达成共识后，答案的正确性 | 评估系统输出质量 |

---

## 快速开始

### 1. 快速测试（Mock LLM）

```bash
# 使用Mock LLM快速验证实验流程
python ex/main.py fault_tolerance --quick-test
```

**预期输出**：
- 7个节点（0-2个恶意节点）
- 3个刁钻问题
- 总耗时 < 2分钟

---

### 2. 完整实验（真实LLM - Qwen）

#### 步骤1：配置API密钥

```bash
# Linux/Mac
export QWEN_API_KEY="your_qwen_api_key"
export QWEN_APP_ID="your_qwen_app_id"

# Windows PowerShell
$env:QWEN_API_KEY="your_qwen_api_key"
$env:QWEN_APP_ID="your_qwen_app_id"

# Windows CMD
set QWEN_API_KEY=your_qwen_api_key
set QWEN_APP_ID=your_qwen_app_id
```

#### 步骤2：运行实验

```bash
# 使用默认配置
python ex/main.py fault_tolerance

# 或指定自定义配置文件
python ex/main.py fault_tolerance --config ex/configs/my_fault_tolerance.yaml
```

#### 步骤3：查看结果

实验运行过程中会实时显示：
```
配置 1/8
  节点数: 9
  恶意节点数: 0 (0.0%)
  Leader类型: honest
  网络延迟: [10, 100]ms
  LLM后端: qwen

  任务 1/5: 一个球拍和一个球总共卖1.10美元。球拍比球贵1.00美元。请问球多少钱？
  类型: math_trap, 难度: easy
    结果: 成功 | Y票: 7, N票: 2
...
```

---

### 3. 分析已有结果

```bash
python ex/main.py fault_tolerance --analyze ex/results/data/fault_tolerance_latest.json
```

**输出**：
1. 统计表格（按恶意节点数分组）
2. 4张可视化图表：
   - 成功率 vs 恶意比例（对比诚实/恶意Leader）
   - 延迟 vs 恶意比例
   - 视图切换次数 vs 恶意比例
   - **容错边界对比图**（关键洞察）

---

## 实验流程图

```
开始
  ↓
加载配置文件
  ↓
对于每个配置 (7种)：
  ↓
  创建9个Agent (其中N个为恶意)
  ↓
  设置Leader类型 (诚实/恶意)
  ↓
  初始化网络和BFT协议
  ↓
  运行5个刁钻问题任务
  ↓
  记录每个任务的：
    - 共识是否成功
    - Y/N投票统计
    - 视图切换次数
    - 各阶段延迟
  ↓
保存结果到JSON
  ↓
生成可视化图表
  ↓
结束
```

---

## 预期结果分析

### 理论预期

根据BFT理论（f/n ≤ 1/3）和LLM特性，预期观察到：

#### 1. 成功率曲线

```
成功率
1.0 |                    ●诚实Leader
    |                  ●   ●恶意Leader
0.8 |                ●
    |              ●   ●
0.6 |            ●       ← 临界限
    |          ●   ●
0.4 |        ●
    |      ●   ●
0.2 |    ●
    |  ●   ●
0.0 +----------------------------------
    0%  11%  22%  33%  恶意节点比例
```

**关键预期**：
- **诚实Leader场景**：
  - 0%恶意：成功率 > 95%
  - 22%恶意：成功率 > 80%
  - 33%恶意：成功率 ≈ 60-70%（临界）

- **恶意Leader场景**：
  - 需要更多视图切换，成功率略低
  - 33%恶意时可能 < 60%

#### 2. 延迟增长

```
延迟(秒)
10 |                     ●诚实Leader
   |                   ●   ●恶意Leader
 8 |                 ●
   |               ●   ●
 6 |             ●       ← 恶意Leader需要更多视图切换
   |           ●   ●
 4 |         ●
   |       ●   ●
 2 |     ●
   |   ●   ●
 0 +-----------------------------
     0%  11%  22%  33%  恶意节点比例
```

#### 3. 视图切换次数

- **诚实Leader**：视图切换较少（仅在Leader出错时）
- **恶意Leader**：视图切换频繁（需要多次换Leader）

---

## 刁钻问题数据集

本实验使用专门设计的 `tricky_questions.json`，包含25个刁钻问题：

### 问题类型分布

| 类型 | 数量 | 示例 | 诱导错误方式 |
|------|-----|------|------------|
| **数学陷阱** | 8 | "球拍和球共1.10美元，球拍贵1美元" | 直觉错误答案 |
| **逻辑陷阱** | 7 | "超过第二名后你是第几名？" | 思维定势 |
| **概率/博弈论** | 4 | "海盗分金问题" | 复杂逻辑推理 |
| **空间/几何** | 3 | "骰子相邻面之和" | 抽象思维 |
| **悖论/哲学** | 3 | "我在说谎" | 无解问题 |

### 问题难度

- **简单**（Easy）：8个 - 大多数LLM能正确回答
- **中等**（Medium）：12个 - 部分LLM可能出错
- **困难**（Hard）：5个 - 多数LLM会出错

**设计理念**：
- 简单问题用于验证基准表现
- 中等问题用于测试容错能力
- 困难问题用于推到极限

---

## 关键假设与局限

### 关键假设

1. **LLM作为Judge是可靠的**：
   - 假设诚实LLM在大多数情况下能正确识别其他agent的答案
   - 实际上LLM的judge能力可能存在偏差

2. **错误独立性**：
   - 假设不同诚实agent的错误是独立的
   - 实际上同一问题可能诱导多个LLM犯相同错误

3. **恶意行为模型**：
   - 当前实现：恶意agent随机投N票或投错答案
   - 实际攻击可能更复杂（如协调攻击）

### 局限性

1. **节点规模限制**：
   - 实验使用9个节点，实际系统可能更大
   - 小规模可能低估容错难度

2. **问题覆盖度**：
   - 25个问题可能不足以覆盖所有场景
   - 需要更多样化的问题类型

3. **LLM选择偏差**：
   - 仅测试1-2种LLM，结论可能不具普适性
   - 不同LLM的容错特性可能不同

---

## 扩展实验建议

### 1. 增加节点规模

测试更大规模的系统：
```yaml
variables:
  num_agents: [15, 21, 27]  # 测试5f+1, 7f+1, 9f+1
  malicious_count: [0, 5, 7, 9]  # 对应的恶意节点数
```

### 2. 测试不同LLM

对比不同LLM的容错特性：
```yaml
variables:
  llm_backend: ['qwen', 'zhipu', 'openai']
```

### 3. 更复杂的恶意策略

当前恶意agent行为较简单，可以增加：
- **协调攻击**：恶意agent相互配合，在关键时刻投错票
- **智能攻击**：根据当前投票情况动态调整策略
- **静默攻击**：恶意agent延迟投票，导致超时

### 4. 引入信誉系统

实现论文中提到的基于区块链的信誉加权投票：
```python
# 伪代码
weight = agent.reputation * stake
weighted_vote = vote * weight
```

---

## 结果解读指南

### 成功的标志

1. **理论验证**：
   - ✅ 在 f/n < 1/3 时，成功率 > 80%
   - ✅ 在 f/n = 1/3 时，成功率 > 60%
   - ✅ 系统能通过视图切换识别并替换恶意Leader

2. **实际问题**：
   - ✅ 诚实agent确实在某些刁钻问题上出错（验证了实验必要性）
   - ✅ 系统仍能达成共识（证明协议鲁棒性）

### 需要警惕的情况

1. **系统失效**：
   - ⚠️ 在 f/n = 22% 时成功率 < 70%
   - ⚠️ 恶意Leader导致系统完全无法共识

2. **LLM问题**：
   - ⚠️ 诚实agent错误率 > 50%（问题太难）
   - ⚠️ 所有agent（包括诚实）都投N票（系统设计问题）

---

## 与论文内容的对应

本实验直接验证论文中的以下内容：

1. **定理1（一致性）**：
   - 实验验证：在 f/n ≤ 1/3 时，系统能达成唯一共识

2. **定理2（活性）**：
   - 实验验证：通过视图切换，系统最终能找到诚实Leader

3. **4.2 抗女巫攻击与信誉机制**：
   - 当前未实现DID，可作为未来扩展

4. **诚实agent可能出错**：
   - 论文核心洞察：BFT4Agent与传统BFT的关键区别
   - 本实验专门设计用于验证这一点

---

## 故障排查

### 常见问题

**Q1: 实验运行时间过长**
- A: 使用真实LLM时，每个任务可能需要1-5分钟。建议：
  - 先用`--quick-test`验证流程
  - 减少`num_tasks`数量
  - 使用更快的LLM模型

**Q2: 成功率异常低（< 50%）**
- A: 检查：
  - API密钥是否配置正确
  - LLM服务是否可用
  - 问题的难度是否过高（可以先测试简单问题）

**Q3: 所有agent都投N票**
- A: 可能原因：
  - Leader的答案确实有问题
  - 问题过于困难，超出LLM能力
  - LLM的judge标准过于严格

**Q4: 视图切换次数过多**
- A: 正常现象，说明：
  - 系统在尝试替换Leader
  - 恶意Leader被正确识别
  - 但如果次数 > 5，可能需要检查配置

---

## 技术细节

### 代码结构

```
ex/experiments/fault_tolerance/
├── __init__.py           # 模块导出
├── experiment.py         # 实验主逻辑
└── README.md            # 本文档
```

### 关键类和方法

- **FaultToleranceExperiment**：实验主类
  - `run()` - 运行完整实验
  - `_run_single_config()` - 运行单个配置
  - `_analyze_results()` - 分析并可视化结果
  - `_plot_fault_tolerance_boundary()` - 绘制容错边界图

### 依赖关系

- 复用 `ex.experiments.latency.consensus.BFT4AgentWithLatency`
- 复用 `ex.experiments.latency.tracker.LatencyTracker`
- 使用新的数据集：`bft4agent-simple/data/tasks/tricky_questions.json`

---

## 版本历史

- **v1.0** (2025-02-06)
  - 初始版本
  - 支持9节点系统，0-33%恶意比例
  - 25个刁钻问题数据集
  - 分别测试诚实/恶意Leader场景
  - 完整的可视化分析

---

## 参考文献

1. Castro, M., & Liskov, B. (1999). Practical Byzantine Fault Tolerance. OSDI.
2. **paper.md** - BFT4Agent协议设计文档
3. **实验设计.md** - 完整的实验设计方案
4. Ye et al. (2025). MAS-GPT: Training LLMs to build LLM-based multi-agent systems. ICML.

---

**作者**：Claude Code
**最后更新**：2025-02-06
**对应论文版本**：v1.0
**实验代码版本**：fault_tolerance v1.0
