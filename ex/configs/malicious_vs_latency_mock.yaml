# 恶意节点比例与延迟关系实验配置文件 - Mock LLM后端

experiment_name: "malicious_vs_latency_experiment_mock"
description: "测试不同恶意节点比例对系统延迟的影响 - Mock LLM后端对比测试"

# 实验变量
variables:
  num_agents: [20]                    # 固定节点数为20
  malicious_count: [1, 2, 3, 4, 5, 6] # 恶意节点数量（对应5%-30%）
  network_delay: [[10, 100]]          # 固定网络延迟为默认值
  llm_backend: ["mock"]               # 使用mock后端进行对比测试

# 任务配置
tasks:
  file: "math_tasks_simple.json"
  num_tasks: 3                        # 每个配置运行3个任务（与qwen测试保持一致）
  shuffle: false

# 全局配置
global:
  timeout: 30.0
  max_retries: 15                     # 增加到15次，因为恶意节点多时可能需要更多视图切换
  mock_accuracy: 1.0                  # Mock LLM的准确率为100%

# LLM API配置（Mock不需要）
llm_api_config:
  qwen:
    api_key: "${QWEN_API_KEY}"
    app_id: "${QWEN_APP_ID}"
    enable_thinking: false
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4"
  deepseek:
    api_key: "${DEEPSEEK_API_KEY}"
    model: "deepseek-chat"
